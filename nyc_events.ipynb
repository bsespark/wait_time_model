{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ed3081",
   "metadata": {},
   "source": [
    "### Ticketmaster Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83090da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\spark\\AppData\\Local\\Temp\\ipykernel_6012\\3074867563.py\", line 1, in <module>\n",
      "    import os, requests, datetime as dt, pandas as pd, time, pytz\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\spark\\AppData\\Local\\Temp\\ipykernel_6012\\3074867563.py\", line 1, in <module>\n",
      "    import os, requests, datetime as dt, pandas as pd, time, pytz\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\spark\\AppData\\Local\\Temp\\ipykernel_6012\\3074867563.py\", line 1, in <module>\n",
      "    import os, requests, datetime as dt, pandas as pd, time, pytz\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 52, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\spark\\AppData\\Local\\Temp\\ipykernel_6012\\3074867563.py\", line 1, in <module>\n",
      "    import os, requests, datetime as dt, pandas as pd, time, pytz\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 66, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py\", line 61, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\spark\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-08: 137 events found\n",
      "2025-08-09: 238 events found\n",
      "Error on 2025-08-10: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2025-08-11: 57 events found\n",
      "2025-08-12: 95 events found\n",
      "2025-08-13: 147 events found\n",
      "2025-08-14: 136 events found\n",
      "   event_date  other_events  largest_capacity  concurrent_event\n",
      "0  2025-08-08           137                 0                 1\n",
      "1  2025-08-09           238                 0                 1\n",
      "2  2025-08-10             0                 0                 0\n",
      "3  2025-08-11            57                 0                 0\n",
      "4  2025-08-12            95                 0                 0\n",
      "5  2025-08-13           147                 0                 0\n",
      "6  2025-08-14           136                 0                 1\n"
     ]
    }
   ],
   "source": [
    "import os, requests, datetime as dt, pandas as pd, time, pytz\n",
    "\n",
    "# ---- CONFIG ----\n",
    "LAT, LON  = 40.6827, -73.9753\n",
    "RADIUS_MI = 12\n",
    "API_KEY   = \"25r7SOxAmwyeYduW911G1xUCePUmbDln\"  # Replace with your real key\n",
    "URL       = \"https://app.ticketmaster.com/discovery/v2/events.json\"\n",
    "\n",
    "NY = pytz.timezone(\"America/New_York\")\n",
    "\n",
    "def to_utc_iso(dt_naive):\n",
    "    \"\"\"Convert a naive NY datetime to UTC ISO string.\"\"\"\n",
    "    return NY.localize(dt_naive).astimezone(pytz.UTC).isoformat()\n",
    "\n",
    "def ticketmaster_day(day: dt.date, target_hour: int = 20, radius: int = RADIUS_MI, verbose: bool = True):\n",
    "    params = {\n",
    "        \"latlong\": f\"{LAT},{LON}\",\n",
    "        \"radius\": radius,\n",
    "        \"unit\": \"miles\",\n",
    "        \"size\": 200,\n",
    "        \"apikey\": API_KEY,\n",
    "        \"page\": 0,\n",
    "        \"startDateTime\": to_utc_iso(dt.datetime.combine(day, dt.time(0,0))),\n",
    "        \"endDateTime\": to_utc_iso(dt.datetime.combine(day, dt.time(23,59,59))),\n",
    "    }\n",
    "    \n",
    "    all_events, caps = [], []\n",
    "    \n",
    "    while True:\n",
    "        js = requests.get(URL, params=params, timeout=20).json()\n",
    "        \n",
    "        if \"errors\" in js or \"fault\" in js:\n",
    "            print(f\"Error on {day}: {js}\")\n",
    "            return {\"event_date\": day, \"other_events\": 0, \"largest_capacity\": 0, \"concurrent_event\": 0}\n",
    "        \n",
    "        evs = js.get(\"_embedded\", {}).get(\"events\", [])\n",
    "        all_events.extend(evs)\n",
    "        \n",
    "        for ev in evs:\n",
    "            for v in ev.get(\"_embedded\", {}).get(\"venues\", []):\n",
    "                cap = v.get(\"capacity\") or v.get(\"venueCapacity\")\n",
    "                if cap:\n",
    "                    caps.append(cap)\n",
    "                    break\n",
    "        \n",
    "        page = js.get(\"page\", {})\n",
    "        if page.get(\"number\", 0) >= page.get(\"totalPages\", 1) - 1:\n",
    "            break\n",
    "        params[\"page\"] += 1\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{day}: {len(all_events)} events found\")\n",
    "    \n",
    "    target_dt = dt.datetime.combine(day, dt.time(target_hour))\n",
    "    concurrent = any(\n",
    "        abs((dt.datetime.fromisoformat(ev[\"dates\"][\"start\"][\"dateTime\"].replace(\"Z\", \"+00:00\"))\n",
    "             .replace(tzinfo=None) - target_dt).total_seconds()) < 3600\n",
    "        for ev in all_events\n",
    "        if ev.get(\"dates\", {}).get(\"start\", {}).get(\"dateTime\")\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"event_date\": day,\n",
    "        \"other_events\": len(all_events),\n",
    "        \"largest_capacity\": max(caps) if caps else 0,\n",
    "        \"concurrent_event\": int(concurrent),\n",
    "    }\n",
    "\n",
    "def ticketmaster_range(start, end, **kwargs) -> pd.DataFrame:\n",
    "    dates = pd.date_range(start, end).date\n",
    "    rows  = [ticketmaster_day(d, **kwargs) for d in dates]\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---- TEST NEXT 7 DAYS ----\n",
    "today = dt.date.today()\n",
    "df_events = ticketmaster_range(today, today + dt.timedelta(days=6))\n",
    "print(df_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7bad3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-05: 105 events found\n",
      "2025-08-06: 146 events found\n",
      "2025-08-07: 129 events found\n",
      "2025-08-08: 138 events found\n",
      "2025-08-09: 234 events found\n",
      "2025-08-10: 149 events found\n",
      "2025-08-11: 57 events found\n",
      "2025-08-12: 95 events found\n",
      "2025-08-13: 147 events found\n",
      "2025-08-14: 135 events found\n",
      "2025-08-15: 128 events found\n",
      "2025-08-16: 229 events found\n",
      "2025-08-17: 127 events found\n",
      "2025-08-18: 41 events found\n",
      "2025-08-19: 94 events found\n",
      "2025-08-20: 132 events found\n",
      "2025-08-21: 146 events found\n",
      "2025-08-22: 139 events found\n",
      "2025-08-23: 229 events found\n",
      "2025-08-24: 164 events found\n",
      "2025-08-25: 85 events found\n",
      "2025-08-26: 125 events found\n",
      "2025-08-27: 147 events found\n",
      "2025-08-28: 160 events found\n",
      "2025-08-29: 147 events found\n",
      "2025-08-30: 250 events found\n",
      "2025-08-31: 188 events found\n",
      "2025-09-01: 54 events found\n",
      "2025-09-02: 101 events found\n",
      "2025-09-03: 145 events found\n",
      "2025-09-04: 131 events found\n",
      "2025-09-05: 158 events found\n",
      "2025-09-06: 238 events found\n",
      "2025-09-07: 184 events found\n",
      "2025-09-08: 45 events found\n",
      "2025-09-09: 94 events found\n",
      "2025-09-10: 133 events found\n",
      "2025-09-11: 130 events found\n",
      "2025-09-12: 128 events found\n",
      "2025-09-13: 214 events found\n",
      "2025-09-14: 155 events found\n",
      "2025-09-15: 43 events found\n",
      "2025-09-16: 77 events found\n",
      "2025-09-17: 120 events found\n",
      "2025-09-18: 115 events found\n",
      "2025-09-19: 133 events found\n",
      "2025-09-20: 223 events found\n",
      "Error on 2025-09-21: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2025-09-22: 43 events found\n",
      "2025-09-23: 105 events found\n",
      "2025-09-24: 137 events found\n",
      "2025-09-25: 134 events found\n",
      "2025-09-26: 135 events found\n",
      "2025-09-27: 240 events found\n",
      "Error on 2025-09-28: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2025-09-29: 42 events found\n",
      "2025-09-30: 90 events found\n",
      "2025-10-01: 139 events found\n",
      "2025-10-02: 124 events found\n",
      "2025-10-03: 117 events found\n",
      "2025-10-04: 216 events found\n",
      "2025-10-05: 143 events found\n",
      "2025-10-06: 31 events found\n",
      "2025-10-07: 83 events found\n",
      "2025-10-08: 104 events found\n",
      "2025-10-09: 119 events found\n",
      "2025-10-10: 127 events found\n",
      "2025-10-11: 211 events found\n",
      "2025-10-12: 171 events found\n",
      "2025-10-13: 39 events found\n",
      "2025-10-14: 87 events found\n",
      "2025-10-15: 120 events found\n",
      "2025-10-16: 115 events found\n",
      "2025-10-17: 121 events found\n",
      "2025-10-18: 211 events found\n",
      "2025-10-19: 144 events found\n",
      "2025-10-20: 37 events found\n",
      "2025-10-21: 84 events found\n",
      "2025-10-22: 114 events found\n",
      "2025-10-23: 118 events found\n",
      "2025-10-24: 124 events found\n",
      "2025-10-25: 202 events found\n",
      "2025-10-26: 138 events found\n",
      "2025-10-27: 34 events found\n",
      "2025-10-28: 78 events found\n",
      "2025-10-29: 115 events found\n",
      "2025-10-30: 113 events found\n",
      "2025-10-31: 99 events found\n",
      "2025-11-01: 190 events found\n",
      "2025-11-02: 127 events found\n",
      "2025-11-03: 30 events found\n",
      "2025-11-04: 75 events found\n",
      "2025-11-05: 98 events found\n",
      "2025-11-06: 101 events found\n",
      "2025-11-07: 113 events found\n",
      "2025-11-08: 203 events found\n",
      "2025-11-09: 142 events found\n",
      "2025-11-10: 34 events found\n",
      "2025-11-11: 69 events found\n",
      "2025-11-12: 110 events found\n",
      "2025-11-13: 96 events found\n",
      "2025-11-14: 104 events found\n",
      "2025-11-15: 188 events found\n",
      "2025-11-16: 127 events found\n",
      "2025-11-17: 22 events found\n",
      "2025-11-18: 68 events found\n",
      "2025-11-19: 108 events found\n",
      "2025-11-20: 105 events found\n",
      "2025-11-21: 104 events found\n",
      "2025-11-22: 192 events found\n",
      "2025-11-23: 133 events found\n",
      "2025-11-24: 45 events found\n",
      "2025-11-25: 75 events found\n",
      "2025-11-26: 131 events found\n",
      "2025-11-27: 10 events found\n",
      "2025-11-28: 154 events found\n",
      "2025-11-29: 187 events found\n",
      "2025-11-30: 95 events found\n",
      "2025-12-01: 26 events found\n",
      "2025-12-02: 73 events found\n",
      "2025-12-03: 102 events found\n",
      "2025-12-04: 108 events found\n",
      "2025-12-05: 102 events found\n",
      "2025-12-06: 191 events found\n",
      "2025-12-07: 137 events found\n",
      "2025-12-08: 23 events found\n",
      "2025-12-09: 67 events found\n",
      "2025-12-10: 107 events found\n",
      "2025-12-11: 101 events found\n",
      "2025-12-12: 97 events found\n",
      "2025-12-13: 191 events found\n",
      "2025-12-14: 130 events found\n",
      "2025-12-15: 29 events found\n",
      "2025-12-16: 75 events found\n",
      "2025-12-17: 105 events found\n",
      "2025-12-18: 92 events found\n",
      "2025-12-19: 92 events found\n",
      "2025-12-20: 179 events found\n",
      "2025-12-21: 124 events found\n",
      "2025-12-22: 66 events found\n",
      "2025-12-23: 108 events found\n",
      "2025-12-24: 30 events found\n",
      "2025-12-25: 37 events found\n",
      "2025-12-26: 109 events found\n",
      "2025-12-27: 150 events found\n",
      "2025-12-28: 123 events found\n",
      "2025-12-29: 69 events found\n",
      "2025-12-30: 118 events found\n",
      "2025-12-31: 110 events found\n",
      "2026-01-01: 105 events found\n",
      "2026-01-02: 119 events found\n",
      "2026-01-03: 145 events found\n",
      "2026-01-04: 77 events found\n",
      "2026-01-05: 20 events found\n",
      "2026-01-06: 43 events found\n",
      "2026-01-07: 65 events found\n",
      "2026-01-08: 57 events found\n",
      "2026-01-09: 55 events found\n",
      "2026-01-10: 104 events found\n",
      "2026-01-11: 75 events found\n",
      "2026-01-12: 17 events found\n",
      "Error on 2026-01-13: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2026-01-14: 64 events found\n",
      "2026-01-15: 51 events found\n",
      "2026-01-16: 52 events found\n",
      "2026-01-17: 99 events found\n",
      "2026-01-18: 82 events found\n",
      "2026-01-19: 15 events found\n",
      "2026-01-20: 31 events found\n",
      "2026-01-21: 44 events found\n",
      "2026-01-22: 43 events found\n",
      "2026-01-23: 40 events found\n",
      "2026-01-24: 78 events found\n",
      "2026-01-25: 55 events found\n",
      "2026-01-26: 15 events found\n",
      "2026-01-27: 35 events found\n",
      "2026-01-28: 46 events found\n",
      "2026-01-29: 51 events found\n",
      "2026-01-30: 41 events found\n",
      "2026-01-31: 80 events found\n",
      "2026-02-01: 61 events found\n",
      "2026-02-02: 11 events found\n",
      "2026-02-03: 33 events found\n",
      "2026-02-04: 43 events found\n",
      "2026-02-05: 46 events found\n",
      "2026-02-06: 34 events found\n",
      "2026-02-07: 64 events found\n",
      "2026-02-08: 44 events found\n",
      "2026-02-09: 9 events found\n",
      "2026-02-10: 28 events found\n",
      "2026-02-11: 34 events found\n",
      "2026-02-12: 181 events found\n",
      "2026-02-13: 178 events found\n",
      "2026-02-14: 62 events found\n",
      "2026-02-15: 56 events found\n",
      "2026-02-16: 11 events found\n",
      "2026-02-17: 23 events found\n",
      "2026-02-18: 32 events found\n",
      "2026-02-19: 30 events found\n",
      "2026-02-20: 28 events found\n",
      "2026-02-21: 51 events found\n",
      "2026-02-22: 36 events found\n",
      "2026-02-23: 8 events found\n",
      "2026-02-24: 25 events found\n",
      "2026-02-25: 33 events found\n",
      "2026-02-26: 34 events found\n",
      "2026-02-27: 34 events found\n",
      "2026-02-28: 63 events found\n",
      "2026-03-01: 47 events found\n",
      "2026-03-02: 13 events found\n",
      "2026-03-03: 27 events found\n",
      "2026-03-04: 32 events found\n",
      "2026-03-05: 33 events found\n",
      "2026-03-06: 25 events found\n",
      "2026-03-07: 53 events found\n",
      "2026-03-08: 37 events found\n",
      "2026-03-09: 7 events found\n",
      "2026-03-10: 25 events found\n",
      "2026-03-11: 29 events found\n",
      "2026-03-12: 26 events found\n",
      "2026-03-13: 22 events found\n",
      "2026-03-14: 45 events found\n",
      "2026-03-15: 25 events found\n",
      "2026-03-16: 14 events found\n",
      "2026-03-17: 18 events found\n",
      "2026-03-18: 28 events found\n",
      "2026-03-19: 22 events found\n",
      "2026-03-20: 20 events found\n",
      "2026-03-21: 37 events found\n",
      "2026-03-22: 27 events found\n",
      "2026-03-23: 12 events found\n",
      "2026-03-24: 18 events found\n",
      "2026-03-25: 23 events found\n",
      "2026-03-26: 20 events found\n",
      "2026-03-27: 23 events found\n",
      "2026-03-28: 39 events found\n",
      "2026-03-29: 34 events found\n",
      "2026-03-30: 3 events found\n",
      "2026-03-31: 20 events found\n",
      "2026-04-01: 22 events found\n",
      "2026-04-02: 25 events found\n",
      "2026-04-03: 16 events found\n",
      "2026-04-04: 34 events found\n",
      "2026-04-05: 20 events found\n",
      "2026-04-06: 6 events found\n",
      "2026-04-07: 14 events found\n",
      "2026-04-08: 16 events found\n",
      "2026-04-09: 15 events found\n",
      "2026-04-10: 14 events found\n",
      "2026-04-11: 20 events found\n",
      "2026-04-12: 18 events found\n",
      "2026-04-13: 6 events found\n",
      "2026-04-14: 11 events found\n",
      "2026-04-15: 13 events found\n",
      "2026-04-16: 11 events found\n",
      "2026-04-17: 12 events found\n",
      "2026-04-18: 23 events found\n",
      "2026-04-19: 15 events found\n",
      "2026-04-20: 6 events found\n",
      "2026-04-21: 11 events found\n",
      "2026-04-22: 12 events found\n",
      "2026-04-23: 13 events found\n",
      "2026-04-24: 24 events found\n",
      "2026-04-25: 35 events found\n",
      "2026-04-26: 15 events found\n",
      "2026-04-27: 6 events found\n",
      "2026-04-28: 11 events found\n",
      "2026-04-29: 9 events found\n",
      "2026-04-30: 10 events found\n",
      "2026-05-01: 13 events found\n",
      "2026-05-02: 22 events found\n",
      "2026-05-03: 17 events found\n",
      "2026-05-04: 5 events found\n",
      "2026-05-05: 10 events found\n",
      "2026-05-06: 10 events found\n",
      "2026-05-07: 10 events found\n",
      "2026-05-08: 12 events found\n",
      "2026-05-09: 22 events found\n",
      "2026-05-10: 16 events found\n",
      "2026-05-11: 6 events found\n",
      "2026-05-12: 9 events found\n",
      "2026-05-13: 8 events found\n",
      "2026-05-14: 9 events found\n",
      "2026-05-15: 10 events found\n",
      "2026-05-16: 19 events found\n",
      "2026-05-17: 14 events found\n",
      "2026-05-18: 5 events found\n",
      "2026-05-19: 9 events found\n",
      "2026-05-20: 8 events found\n",
      "2026-05-21: 10 events found\n",
      "2026-05-22: 11 events found\n",
      "2026-05-23: 17 events found\n",
      "2026-05-24: 14 events found\n",
      "2026-05-25: 5 events found\n",
      "2026-05-26: 8 events found\n",
      "2026-05-27: 7 events found\n",
      "2026-05-28: 9 events found\n",
      "2026-05-29: 9 events found\n",
      "2026-05-30: 17 events found\n",
      "Error on 2026-05-31: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2026-06-01: 3 events found\n",
      "2026-06-02: 6 events found\n",
      "2026-06-03: 6 events found\n",
      "2026-06-04: 7 events found\n",
      "2026-06-05: 8 events found\n",
      "2026-06-06: 11 events found\n",
      "2026-06-07: 8 events found\n",
      "2026-06-08: 3 events found\n",
      "2026-06-09: 5 events found\n",
      "2026-06-10: 5 events found\n",
      "2026-06-11: 5 events found\n",
      "2026-06-12: 5 events found\n",
      "2026-06-13: 9 events found\n",
      "Error on 2026-06-14: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2026-06-15: 3 events found\n",
      "2026-06-16: 5 events found\n",
      "2026-06-17: 5 events found\n",
      "2026-06-18: 6 events found\n",
      "2026-06-19: 6 events found\n",
      "2026-06-20: 9 events found\n",
      "2026-06-21: 9 events found\n",
      "2026-06-22: 3 events found\n",
      "2026-06-23: 6 events found\n",
      "2026-06-24: 6 events found\n",
      "2026-06-25: 6 events found\n",
      "2026-06-26: 7 events found\n",
      "2026-06-27: 9 events found\n",
      "2026-06-28: 8 events found\n",
      "2026-06-29: 5 events found\n",
      "2026-06-30: 15 events found\n",
      "2026-07-01: 18 events found\n",
      "2026-07-02: 5 events found\n",
      "2026-07-03: 3 events found\n",
      "2026-07-04: 2 events found\n",
      "2026-07-05: 6 events found\n",
      "2026-07-06: 1 events found\n",
      "2026-07-07: 4 events found\n",
      "Error on 2026-07-08: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2026-07-09: 3 events found\n",
      "Error on 2026-07-10: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2026-07-11: 6 events found\n",
      "2026-07-12: 4 events found\n",
      "2026-07-13: 1 events found\n",
      "2026-07-14: 3 events found\n",
      "2026-07-15: 5 events found\n",
      "2026-07-16: 3 events found\n",
      "Error on 2026-07-17: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2026-07-18: 6 events found\n",
      "2026-07-19: 4 events found\n",
      "2026-07-20: 1 events found\n",
      "2026-07-21: 3 events found\n",
      "2026-07-22: 5 events found\n",
      "2026-07-23: 3 events found\n",
      "Error on 2026-07-24: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2026-07-25: 6 events found\n",
      "2026-07-26: 4 events found\n",
      "2026-07-27: 1 events found\n",
      "2026-07-28: 3 events found\n",
      "2026-07-29: 5 events found\n",
      "Error on 2026-07-30: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2026-07-31: 4 events found\n",
      "2026-08-01: 5 events found\n",
      "2026-08-02: 3 events found\n",
      "Error on 2026-08-03: {'fault': {'faultstring': 'Spike arrest violation. Allowed rate : MessageRate{messagesPerPeriod=5, periodInMicroseconds=1000000, maxBurstMessageCount=1.0}', 'detail': {'errorcode': 'policies.ratelimit.SpikeArrestViolation'}}}\n",
      "2026-08-04: 2 events found\n",
      "2026-08-05: 4 events found\n",
      " CSV updated. Total records: 366\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"ticketmaster_events.csv\"\n",
    "\n",
    "def update_ticketmaster_csv(start_date, end_date):\n",
    "    # Step 1: Pull new data\n",
    "    new_df = ticketmaster_range(start_date, end_date)\n",
    "    \n",
    "    # Step 2: If CSV exists, append only missing dates\n",
    "    if os.path.exists(CSV_PATH):\n",
    "        existing_df = pd.read_csv(CSV_PATH, parse_dates=[\"event_date\"])\n",
    "        combined_df = pd.concat([existing_df, new_df])\n",
    "        combined_df = combined_df.drop_duplicates(subset=[\"event_date\"], keep=\"last\")\n",
    "    else:\n",
    "        combined_df = new_df\n",
    "    \n",
    "    # Step 3: Save back to CSV\n",
    "    combined_df.to_csv(CSV_PATH, index=False)\n",
    "    print(f\" CSV updated. Total records: {len(combined_df)}\")\n",
    "\n",
    "# Example: update with 1 year of events from today\n",
    "today = dt.date.today()\n",
    "update_ticketmaster_csv(today, today + dt.timedelta(days=365))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e6b90",
   "metadata": {},
   "source": [
    "### Eventbrite only works for event organizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a5f6cd",
   "metadata": {},
   "source": [
    "### SeatGeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6edd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests, datetime as dt, pandas as pd\n",
    "\n",
    "# SG_ID     = \"YOUR_CLIENT_ID\"\n",
    "# LAT, LON  = 40.6827, -73.9753\n",
    "# RADIUS    = \"12mi\"\n",
    "\n",
    "# def seatgeek_day(day: dt.date):\n",
    "#     params = {\n",
    "#         \"lat\": LAT, \"lon\": LON, \"range\": RADIUS,\n",
    "#         \"datetime_utc.gte\": f\"{day:%Y-%m-%d}T00:00:00\",\n",
    "#         \"datetime_utc.lte\": f\"{day:%Y-%m-%d}T23:59:59\",\n",
    "#         \"client_id\": SG_ID,\n",
    "#         \"per_page\": 500, \"page\": 1\n",
    "#     }\n",
    "#     events, capacities = [], []\n",
    "#     while True:\n",
    "#         js = requests.get(\"https://api.seatgeek.com/2/events\", params=params, timeout=15).json()\n",
    "#         events += js[\"events\"]\n",
    "#         for e in js[\"events\"]:\n",
    "#             cap = e[\"venue\"].get(\"capacity\")\n",
    "#             if cap: capacities.append(cap)\n",
    "#         if params[\"page\"] >= js[\"meta\"][\"total_pages\"]: break\n",
    "#         params[\"page\"] += 1\n",
    "\n",
    "#     return {\n",
    "#         \"event_date\"      : day,\n",
    "#         \"other_events\"    : len(events),\n",
    "#         \"largest_capacity\": max(capacities) if capacities else 0\n",
    "#     }\n",
    "\n",
    "# # range helper\n",
    "# def seatgeek_range(start, end):\n",
    "#     dates = pd.date_range(start, end).date\n",
    "#     return pd.DataFrame([seatgeek_day(d) for d in dates])\n",
    "\n",
    "# sg_df = seatgeek_range \"2025-07-01\", \"2025-07-31\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
